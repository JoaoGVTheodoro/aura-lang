"""
Complete recursive descent parser for Aura.
Handles expressions, control flow, functions, classes, and more.
"""
import re
import sys
from transpiler.ast import *

# ==============================================================================
# Tokenizer
# ==============================================================================

class Token:
    def __init__(self, type, value, line, column):
        self.type = type
        self.value = value
        self.line = line
        self.column = column

    def __repr__(self):
        return f"Token({self.type}, {repr(self.value)})"

class Tokenizer:
    def __init__(self, source):
        self.source = source
        self.pos = 0
        self.line = 1
        self.column = 1
        self.tokens = []
    
    def tokenize(self):
        length = len(self.source)
        while self.pos < length:
            char = self.source[self.pos]
            
            # Whitespace
            if char.isspace():
                if char == '\n':
                    self.line += 1
                    self.column = 1
                else:
                    self.column += 1
                self.pos += 1
                continue
            
            # Comments
            if char == '/' and self.pos + 1 < length and self.source[self.pos + 1] == '/':
                while self.pos < length and self.source[self.pos] != '\n':
                    self.pos += 1
                continue
            
            # Identifiers and Keywords
            if char.isalpha() or char == '_':
                start = self.pos
                while self.pos < length and (self.source[self.pos].isalnum() or self.source[self.pos] == '_'):
                    self.pos += 1
                value = self.source[start:self.pos]
                
                # F-string support (special case: identifier 'f' followed by quote)
                if value == 'f' and self.pos < length and self.source[self.pos] in ('"', "'"):
                    quote = self.source[self.pos]
                    self.pos += 1 # skip quote
                    start_str = self.pos
                    # TODO: handle escaped quotes and expressions inside f-string properly
                    while self.pos < length and self.source[self.pos] != quote:
                        if self.source[self.pos] == '\n':
                           self.line += 1
                        self.pos += 1
                    str_value = self.source[start_str:self.pos]
                    self.pos += 1 # skip closing
                    self.column += (self.pos - start)
                    self.tokens.append(Token('FSTRING', str_value, self.line, self.column))
                    continue

                self.column += (self.pos - start)
                self.tokens.append(Token('IDENT', value, self.line, self.column))
                continue
            
            # Numbers
            if char.isdigit():
                start = self.pos
                while self.pos < length and self.source[self.pos].isdigit():
                    self.pos += 1
                
                # Check for float dot vs range (..)
                is_float = False
                if self.pos < length and self.source[self.pos] == '.':
                    # Peek next to see if it's a digit (float) or dot (range)
                    if self.pos + 1 < length and self.source[self.pos + 1].isdigit():
                        is_float = True
                        self.pos += 1 # consume dot
                        while self.pos < length and self.source[self.pos].isdigit():
                            self.pos += 1
                    # If it's another dot, it's a range, so don't consume it here
                
                value = self.source[start:self.pos]
                self.column += (self.pos - start)
                
                if is_float:
                    self.tokens.append(Token('FLOAT', float(value), self.line, self.column))
                else:
                    self.tokens.append(Token('INT', int(value), self.line, self.column))
                continue
            
            # Strings
            if char in ('"', "'"):
                quote = char
                self.pos += 1
                start = self.pos
                while self.pos < length and self.source[self.pos] != quote:
                    if self.source[self.pos] == '\\':
                        self.pos += 2 # Skip escaped char
                        continue
                    if self.source[self.pos] == '\n':
                        self.line += 1
                    self.pos += 1
                value = self.source[start:self.pos]
                self.pos += 1 # Skip closing quote
                self.column += (self.pos - start + 2)
                self.tokens.append(Token('STRING', value, self.line, self.column))
                continue
            
            # Operators involving multiple chars
            # Check 3 chars first
            if self.pos + 2 < length:
                three_chars = self.source[self.pos:self.pos+3]
                if three_chars in ('..<', '...'):
                    self.tokens.append(Token('OP', three_chars, self.line, self.column))
                    self.pos += 3
                    self.column += 3
                    continue
            
            if self.pos + 1 < length:
                two_chars = self.source[self.pos:self.pos+2]
                if two_chars in ('==', '!=', '<=', '>=', '->', '=>', '&&', '||', '+=', '-=', '*=', '/=', '..', '??', '?:', '|>', '**', '?.', '?['):
                    self.tokens.append(Token('OP', two_chars, self.line, self.column))
                    self.pos += 2
                    self.column += 2
                    continue
            
            # Single char operators
            self.tokens.append(Token('OP', char, self.line, self.column))
            self.pos += 1
            self.column += 1
        
        self.tokens.append(Token('EOF', '', self.line, self.column))
        return self.tokens

# ==============================================================================
# Parser
# ==============================================================================

class Parser:
    def __init__(self, tokens):
        self.tokens = tokens
        self.pos = 0
    
    # --- Token Management ---
    def peek(self, offset=0):
        if self.pos + offset < len(self.tokens):
            return self.tokens[self.pos + offset]
        return self.tokens[-1]
    
    def consume(self, expected_type=None, expected_value=None):
        if self.pos >= len(self.tokens):
            raise SyntaxError("Unexpected EOF")
        token = self.tokens[self.pos]
        # print(f"DEBUG: consume {token} pos={self.pos}")
        self.pos += 1
        if expected_type and token.type != expected_type:
            raise SyntaxError(f"Expected {expected_type} but got {token.type} '{token.value}' at {token.line}:{token.column}")
        if expected_value and token.value != expected_value:
            raise SyntaxError(f"Expected '{expected_value}' but got '{token.value}' at {token.line}:{token.column}")
        return token
    
    def match(self, value):
        token = self.peek()
        if token.value == value:
            self.pos += 1
            return True
        return False
    
    def check(self, value):
        return self.peek().value == value
    
    def check_type(self, type_name):
        return self.peek().type == type_name

    # --- Main Entry Point ---
    def parse(self):
        statements = []
        while self.peek().type != 'EOF':
            stmt = self.parse_statement()
            if stmt:
                statements.append(stmt)
        return Program(statements)

    # --- Statements ---
    def parse_statement(self):
        token = self.peek()
        
        if token.value == 'let':
            return self.parse_var_decl()
        elif token.value == 'const':
            return self.parse_const_decl()
        elif token.value == 'def' or token.value == 'fn' or token.value == 'async':
            return self.parse_function_decl()
        elif token.value == 'class':
            return self.parse_class_decl()
        elif token.value == 'module':
            return self.parse_module_decl()
        elif token.value == 'type':
             return self.parse_type_decl()
        elif token.value == 'trait':
             return self.parse_trait_decl()
        elif token.value == 'import':
             return self.parse_import_stmt()
        elif token.value == 'if':
            return self.parse_if_stmt()
        elif token.value == 'unless':
            return self.parse_unless_stmt()
        elif token.value == 'while':
            return self.parse_while_stmt()
        elif token.value == 'until':
            return self.parse_until_stmt()
        elif token.value == 'for':
            return self.parse_for_stmt()
        elif token.value == 'loop':
            return self.parse_loop_stmt()
        elif token.value == 'return':
            return self.parse_return_stmt()
        elif token.value == 'break':
            self.consume()
            if self.check(';'): self.consume()
            return BreakStmt()
        elif token.value == 'continue':
            self.consume()
            if self.check(';'): self.consume()
            return ContinueStmt()
        elif token.value == 'guard':
            return self.parse_guard_stmt()
        
        elif token.value == 'assert':
            return self.parse_assert_stmt()

        elif token.value == 'try':
            return self.parse_try_stmt()
        elif token.value == 'with':
            return self.parse_with_stmt()
        elif token.value == 'match':
            return self.parse_match_stmt()
        elif token.value == 'await':
             # await as statement (expression ignored)
             expr = self.parse_expression()
             if self.check(';'): self.consume()
             return ExprStmt(expr)
        elif token.value == '@':
             # Parse decorators
             decorators = []
             while self.match('@'):
                 dec_name = self.consume(expected_type='IDENT').value
                 dec_args = []
                 if self.match('('):
                     if not self.check(')'):
                         while True:
                             dec_args.append(self.parse_expression())
                             if not self.match(','): break
                     self.consume(expected_value=')')
                 decorators.append(Decorator(dec_name, dec_args))
             
             # Next must be function or class
             if self.check('def') or self.check('fn') or self.check('async'):
                 decl = self.parse_function_decl()
                 decl.decorators = decorators
                 return decl
             elif self.check('class'):
                 decl = self.parse_class_decl()
                 decl.decorators = decorators 
                 # Note: ClassDecl AST node check needed. 
                 # If ClassDecl doesn't support decorators arg in __init__, we set definition attribute if possible
                 # Or update ClassDecl.
                 return decl
             else:
                 raise SyntaxError(f"Decorators must precede function or class, got {self.peek()}")
             
        elif token.value == 'case':
            return self.parse_case_stmt()

        elif token.value == ';':
            self.consume()
            return None
        # elif token.value == '}' - Let parse_expression failure handle it
        
        # Expression statement
        expr = self.parse_expression()
        if self.check(';'):
            self.consume()
        return ExprStmt(expr)

    def parse_block(self):
        self.consume(expected_value='{')
        statements = []
        while not self.check('}') and not self.check('EOF'):
            stmt = self.parse_statement()
            if stmt:
                statements.append(stmt)
        self.consume(expected_value='}')
        return statements

    # --- Declarations ---
    def parse_var_decl(self):
        self.consume(expected_value='let')
        mutable = False
        if self.match('mut'):
            mutable = True
        
        # Destructuring check (if starts with { or [ or ()
        name = ""
        if self.check('{') or self.check('[') or self.check('('):
            # Capture tokens until we hit ':' or '='
            # Basic balanced consumption
            # This is a heuristic to get the pattern string for Python
            # A full implementation would parse a Pattern node.
            
            stack = []
            start_pos = self.pos
            while True:
                tok = self.peek() 
                if tok.value in '([{':
                    stack.append(tok.value)
                elif tok.value in ')]}':
                    if stack: stack.pop()
                
                if (tok.value == ':' or tok.value == '=') and not stack:
                    break
                
                # Check EOF
                if tok.type == 'EOF': break
                
                # Consume
                self.consume()
            
            # Reconstruct string from tokens range
            # This is tricky because we don't have source slice easily from tokens logic above
            # But we can reconstruct from tokens values
            pat_tokens = self.tokens[start_pos:self.pos]
            
            # Simple spacing reconstruction
            parts = []
            for i, t in enumerate(pat_tokens):
                parts.append(str(t.value))
                # Add heuristic grouping?
                # Python is picky about spaces? No.
                # (x,y) is fine.
                
            # If we just join everything, we might get (x,y).
            # But tokens are: '(', 'x', ',', 'y', ')'
            # join -> "(x, y)"
            # Let's try to just join with spaces, assuming Python handles spaces.
             # Actually Tokenizer stripped spaces.
             # But ( x , y ) is valid python.
            name = " ".join(t.value for t in pat_tokens)
            
            # Specific replacement for spread operator in list destructuring
            # Aura: *rest. Python: *rest. Tokenizer: * rest (OP, IDENT).
            # " * rest " -> "*rest".
            name = name.replace("* ", "*")

        else:
             name = self.consume(expected_type='IDENT').value
        type_annotation = None
        
        if self.match(':'):
            type_annotation = self.parse_type()
        
        value = None
        if self.match('='):
            value = self.parse_expression()
        
        if self.check(';'):
            self.consume()
            
        return VarDecl(name, mutable, type_annotation, value)

    def parse_const_decl(self):
        self.consume(expected_value='const')
        name = self.consume(expected_type='IDENT').value
        type_annotation = None
        if self.match(':'):
            type_annotation = self.parse_type()
        
        self.consume(expected_value='=')
        value = self.parse_expression()
        if self.check(';'): self.consume()
        return ConstDecl(name, type_annotation, value)

    def parse_function_decl(self):
        # Support both 'def' and 'fn'
        is_async = False
        if self.check('async'):
            self.consume()
            is_async = True
            
        if self.check('def'): self.consume()
        else: self.consume(expected_value='fn')
            
        name = self.consume(expected_type='IDENT').value
        
        # Generic params: fn foo[T](...) OR fn foo<T>(...)
        type_params = []
        if self.match('[') or self.match('<'):
            while True:
                type_params.append(self.consume(expected_type='IDENT').value) 
                if not self.match(','):
                    break
            if self.check(']'): self.consume()
            else: self.consume(expected_value='>')
        
        self.consume(expected_value='(')
        params = []
        if not self.check(')'):
            while True:
                # Handle *args and **kwargs
                is_variadic = False
                if self.match('*'):
                    is_variadic = True
                    
                p_name = self.consume(expected_type='IDENT').value
                p_type = None
                if self.match(':'):
                    p_type = self.parse_type()
                
                default = None
                if self.match('='):
                    default = self.parse_expression()
                    
                params.append(Parameter(p_name, p_type, default, is_variadic=is_variadic))
                if not self.match(','):
                    break
        self.consume(expected_value=')')
        
        return_type = None
        if self.match('->'):
            return_type = self.parse_type()
        
        # Handle expression body: fn foo() = expr
        if self.match('='):
             expr = self.parse_expression()
             # Wrap in return stmt
             body = [ReturnStmt(expr)]
        else:
            body = self.parse_block()
            
        return FunctionDecl(name, params, return_type, body, is_async=is_async, type_params=type_params)

    def parse_class_decl(self):
        self.consume(expected_value='class')
        name = self.consume(expected_type='IDENT').value
        
        # Generics
        if self.match('[') or self.match('<'):
            while True:
                self.consume(expected_type='IDENT')
                if not self.match(','): break
            if self.check(']'): self.consume()
            else: self.consume(expected_value='>')

        base_class = None
        # Support both ': Base' and '(Base)' syntax (or 'extends Base')
        if self.match('('):
            base_class = self.consume(expected_type='IDENT').value
            self.consume(expected_value=')')
        elif self.match(':'):
             base_class = self.consume(expected_type='IDENT').value
        elif self.match('extends'):
             base_class = self.consume(expected_type='IDENT').value
            
        self.consume(expected_value='{')
        members = []
        while not self.check('}') and not self.check('EOF'):
            visibility = 'public'
            is_static = False
            is_volatile = False
            
            # Parse modifiers
            while True:
                if self.match('public'): visibility = 'public'
                elif self.match('private'): visibility = 'private'
                elif self.match('protected'): visibility = 'protected'
                elif self.match('static'): is_static = True
                elif self.match('volatile') or self.match('volatily'): is_volatile = True
                else: break

            # Check for methods
            decorators = []
            while self.match('@'):
                dec_name = self.consume(expected_type='IDENT').value
                decorators.append(dec_name)
                if dec_name == 'staticmethod': is_static = True
                
            if self.check('def') or self.check('fn'):
                func = self.parse_function_decl()
                members.append(Method(func.name, func.params, func.return_type, func.body, 
                                     is_static=is_static, visibility=visibility, is_volatile=is_volatile))
            else:
                 # Fields: x: Int = 1
                if self.check('}') or self.check('EOF'): break
                if self.peek().value in ('let', 'mut'):
                    self.consume()
                if self.peek().type == 'IDENT':
                    field_name = self.consume().value
                    t = None
                    if self.match(':'):
                        t = self.parse_type()
                    v = None
                    if self.match('='):
                        v = self.parse_expression()
                    
                    if self.check(';'): self.consume()
                    members.append(VarDecl(field_name, True, t, v, 
                                          visibility=visibility, is_static=is_static, is_volatile=is_volatile))
                else:
                    raise SyntaxError(f"Unexpected token in class: {self.peek()}")
        
        self.consume(expected_value='}')
        return ClassDecl(name, members, base_class)
    def parse_module_decl(self):
        self.consume(expected_value='module')
        name = self.consume(expected_type='IDENT').value
        # Handle nested module names if needed (e.g. stdlib.collections)
        while self.match('.'):
            name += "." + self.consume(expected_type='IDENT').value
            
        body = self.parse_block()
        # For now, return a wrapper or just the body statements flatted?
        # Let's treat it as a block of statements but ignoring the namespace for transpiling simplicity?
        # Or return a ModuleDecl node (which we might need to add to AST)
        # Existing AST might not have ModuleDecl. Let's return a BlockExpr/Stmt?
        # Actually proper way: add ModuleDecl to AST or just return flattened statements if Python doesn't need modules.
        # Python uses files as modules. 'module X { ... }' might map to class X or just top-level code?
        # Given 'transpiler/ast.py' probably doesn't have ModuleDecl, let's treat it as namespace (Class) or flat.
        # comprehensive.aura uses 'type' inside module.
        # Let's verify AST.
        # Check if ModuleDecl exists.
        return ClassDecl(name, body, None) # Treat module as class for now

    def parse_type_decl(self):
        self.consume(expected_value='type')
        name = self.consume(expected_type='IDENT').value
        
        # Generics: type Result<T, E>
        if self.match('<'):
            while True:
                self.consume(expected_type='IDENT')
                if not self.match(','): break
            self.consume(expected_value='>')
            
        self.consume(expected_value='=')
        
        # Parse the type definition
        # It could be: Ok(T) | Err(E) (UnionDecl?)
        # Or: { ... } (Struct/Dict)
        
        if self.check('{'):
            # Struct/Record type: { x: int, y: int }
            # parse_dict_or_block might be useful but we need Types not Exprs
            self.consume(expected_value='{')
            while not self.check('}'):
                 # id: type
                 if self.peek().type == 'IDENT':
                     self.consume()
                     self.consume(expected_value=':')
                     self.parse_type()
                     if self.check(','): self.consume()
                 else:
                     break
            self.consume(expected_value='}')
        else:
            # Type alias or Union or ADT
            while True:
                # Parse the type or variant name
                self.parse_type()
                
                # valid ADT: Variant(Type, Type)
                if self.match('('):
                    while not self.check(')'):
                        self.parse_type()
                        if self.match(','): pass
                    self.consume(expected_value=')')
                
                if not self.match('|'):
                    break
                    
        if self.check(';'): self.consume()
        return TypeDecl(name, "Type") # Placeholder node

    # --- Type Parsing ---
    def parse_type(self):
        token = self.consume()
        t_name = str(token.value)
        
        # Function type: (T) -> R
        if t_name == '(':
             # Parse arg types
             args = []
             if not self.check(')'):
                 while True:
                     args.append(self.parse_type())
                     if not self.match(','): break
             self.consume(expected_value=')')
             self.consume(expected_value='->')
             ret = self.parse_type()
             return f"({', '.join(str(a) for a in args)}) -> {ret}"
             
        if t_name == '[':
             # Array/List type [T] or [T, U]
             arg = self.parse_type()
             while self.match(','):
                 arg += ", " + self.parse_type()
             self.consume(expected_value=']')
             return f"List[{arg}]" # Map to List type for Python

        while True:
            # Generics: List[Int] (Python/Aura legacy) OR Result<T> (Aura new?)
            if self.match('['):
                arg = self.parse_type()
                while self.match(','):
                     arg += ", " + self.parse_type()
                self.consume(expected_value=']')
                t_name += f"[{arg}]"
            elif self.match('<'):
                arg = self.parse_type()
                while self.match(','):
                     arg += ", " + self.parse_type()
                self.consume(expected_value='>')
                t_name += f"[{arg}]" # Map <T> to [T] for Python typing compatibility
            # Optional: String?
            elif self.match('?'):
                t_name += "?"
            # Union: Int | Str
            elif self.match('|'):
                rhs = self.parse_type()
                t_name += f" | {rhs}"
            else:
                break
        return t_name

    def parse_import_stmt(self):
        self.consume(expected_value='import')
        module = self.consume(expected_type='IDENT').value
        while self.match('.'):
            module += "." + self.consume(expected_type='IDENT').value
            
        items = []
        if self.match('{'):
            while True:
                items.append(self.consume(expected_type='IDENT').value)
                if not self.match(','): break
            self.consume(expected_value='}')
            
        if self.check(';'): self.consume()
        return ImportStmt(module, items)

    def parse_trait_decl(self):
        self.consume(expected_value='trait')
        name = self.consume(expected_type='IDENT').value
        self.consume(expected_value='{')
        # Traits usually have method signatures
        members = []
        while not self.check('}'):
             # def foo(...) -> Type
             if self.check('def') or self.check('fn'):
                 self.consume() # eat def/fn
                 m_name = self.consume(expected_type='IDENT').value
                 self.consume(expected_value='(')
                 # skip params parsing for now or do full parse? 
                 # TraitDecl needs signatures.
                 # Let's reuse parameter parsing but without body
                 params = []
                 if not self.check(')'):
                     while True:
                         # Simplified param parsing for trait
                         if self.check_type('IDENT'): p_name = self.consume().value
                         else: p_name = '_'
                         
                         if self.match(':'): self.parse_type()
                         if self.match('='): self.parse_expression()
                         if not self.match(','): break
                 self.consume(expected_value=')')
                 
                 ret_type = None
                 if self.match('->'):
                     ret_type = self.parse_type()
                     
                 # Trait methods might not have body, or default body?
                 body = None
                 if self.match('{'):
                     body = self.parse_block() # Default implementation?
                 
                 # We need a TraitMethod node? Or just Method with no body?
                 # using Method(..., body=None)
                 members.append(Method(m_name, [], ret_type, body)) 
             elif self.check('}'): 
                 break
             else:
                 self.pos += 1 # Skip unknown
                 
        self.consume(expected_value='}')
        return TraitDecl(name, members)
        token = self.consume()
        t_name = str(token.value)
        
        # Function type: (T) -> R
        if t_name == '(':
             # Parse arg types
             args = []
             if not self.check(')'):
                 while True:
                     args.append(self.parse_type())
                     if not self.match(','): break
             self.consume(expected_value=')')
             self.consume(expected_value='->')
             ret = self.parse_type()
             return f"({', '.join(str(a) for a in args)}) -> {ret}"

        while True:
            # Generics: List[Int] (Python/Aura legacy) OR Result<T> (Aura new?)
            if self.match('['):
                arg = self.parse_type()
                while self.match(','):
                     arg += ", " + self.parse_type()
                self.consume(expected_value=']')
                t_name += f"[{arg}]"
            elif self.match('<'):
                arg = self.parse_type()
                while self.match(','):
                     arg += ", " + self.parse_type()
                self.consume(expected_value='>')
                t_name += f"[{arg}]" # Map <T> to [T] for Python typing compatibility
            # Optional: String?
            elif self.match('?'):
                t_name += "?"
            # Union: Int | Str
            elif self.match('|'):
                rhs = self.parse_type()
                t_name += f" | {rhs}"
            else:
                break
        return t_name

    # --- Control Flow ---
    def parse_if_stmt(self):
        self.consume(expected_value='if')
        cond = self.parse_expression()
        then_body = self.parse_block()
        else_body = None
        if self.match('else'):
            if self.check('if'):
                else_body = [self.parse_if_stmt()]
            else:
                else_body = self.parse_block()
        return IfStmt(cond, then_body, else_body)

    def parse_unless_stmt(self):
        self.consume(expected_value='unless')
        cond = self.parse_expression()
        body = self.parse_block()
        return UnlessStmt(cond, body)

    def parse_while_stmt(self):
        self.consume(expected_value='while')
        cond = self.parse_expression()
        body = self.parse_block()
        return WhileStmt(cond, body)

    def parse_until_stmt(self):
        self.consume(expected_value='until')
        cond = self.parse_expression()
        body = self.parse_block()
        return UntilStmt(cond, body)

    def parse_loop_stmt(self):
        self.consume(expected_value='loop')
        body = self.parse_block()
        return LoopStmt(body)

    def parse_for_stmt(self):
        self.consume(expected_value='for')
        # Check for parenthesis (optional in Aura but good to handle)
        has_paren = self.match('(')
        
        # Supports: for x in ... OR for (i, x) in ...
        targets = []
        if self.check_type('IDENT'):
             targets.append(self.consume().value)
        
        while self.match(','):
             targets.append(self.consume(expected_type='IDENT').value)
        
        if len(targets) == 1:
             pattern = IdentifierPattern(targets[0])
        else:
             pattern = ListPattern([IdentifierPattern(t) for t in targets])

        if has_paren:
             self.consume(expected_value=')')
        
        self.consume(expected_value='in')
        iterable = self.parse_expression()
        
        step = None
        if self.match('step'):
            step = self.parse_expression()
            
        body = self.parse_block()
        return ForStmt(pattern, iterable, body, step)

    def parse_return_stmt(self):
        self.consume(expected_value='return')
        val = None
        if not self.check(';') and not self.check('}'):
            val = self.parse_expression()
        if self.check(';'): self.consume()
        return ReturnStmt(val)

    def parse_guard_stmt(self):
        self.consume(expected_value='guard')
        cond = self.parse_expression()
        self.consume(expected_value='else')
        body = self.parse_block()
        if self.check(';'): self.consume()
        return GuardStmt(cond, body)

    def parse_try_stmt(self):
        self.consume(expected_value='try')
        try_body = self.parse_block()
        catch_clauses = []
        while self.match('catch'):
            exc_type = None
            # Check if type is provided
            if self.check_type('IDENT') and self.peek().value != '{':
                 exc_type = self.consume().value
            
            var_name = None
            if exc_type and self.check_type('IDENT') and self.peek().value != '{' and self.peek().value != 'as':
                 var_name = self.consume().value
            elif exc_type and self.match('as'):
                 var_name = self.consume(expected_type='IDENT').value
                 
            body = self.parse_block()
            catch_clauses.append(CatchClause(exc_type, var_name, body))
        
        finally_body = None
        if self.match('finally'):
            finally_body = self.parse_block()
            
        return TryStmt(try_body, catch_clauses, finally_body)
    
    def parse_with_stmt(self):
        self.consume(expected_value='with')
        items = []
        while True:
            expr = self.parse_expression(11) # Precedence > 10 to avoid consuming 'as'
            var_name = None
            if self.match('as'):
                var_name = self.consume(expected_type='IDENT').value
            items.append((expr, var_name))
            
            if not self.match(','):
                break
        
        body = self.parse_block()
        return WithStmt(items, body)
    
    def parse_match_stmt(self):
        self.consume(expected_value='match')
        expr = self.parse_expression()
        self.consume(expected_value='{')
        cases = []
        while not self.check('}') and not self.check('EOF'):
             # case pattern { ... } OR pattern -> stmt
             is_case_kw = self.match('case')
             pat_node = None
             
             # Parse pattern (simplified as expr for now)
             pattern_expr = self.parse_expression()
             
             if isinstance(pattern_expr, Identifier) and pattern_expr.name == '_':
                pat_node = WildcardPattern()
             elif isinstance(pattern_expr, (IntLiteral, StrLiteral, BoolLiteral)):
                pat_node = LiteralPattern(pattern_expr)
             elif isinstance(pattern_expr, Identifier):
                 pat_node = IdentifierPattern(pattern_expr.name)
             elif isinstance(pattern_expr, (TupleLiteral, ListLiteral)):
                 # Convert tuple/list literal to ListPattern for destructuring
                 
                 patterns = []
                 for elem in (pattern_expr.elements if isinstance(pattern_expr.elements, list) else []):
                     if isinstance(elem, Identifier):
                         patterns.append(IdentifierPattern(elem.name))
                     elif isinstance(elem, (IntLiteral, StrLiteral, BoolLiteral)):
                         patterns.append(LiteralPattern(elem))
                     elif isinstance(elem, UnaryOp) and elem.op == '*':
                         # This is the *rest part
                         if isinstance(elem.operand, Identifier):
                             rest_pattern = IdentifierPattern(elem.operand.name)
                             # Return early or handle as rest
                             pat_node = ListPattern(patterns, rest_pattern=rest_pattern)
                             break
                     else:
                         # Fallback/Recurse needed for nested? For now literal fallback
                         patterns.append(LiteralPattern(elem))
                 
                 pat_node = ListPattern(patterns)
             elif isinstance(pattern_expr, CallExpr):
                 # Convert CallExpr to ConstructorPattern (e.g. Some(x), Err(msg))
                 
                 pat_name = pattern_expr.func.name if isinstance(pattern_expr.func, Identifier) else "unknown"
                 subpatterns = []
                 for arg in pattern_expr.args:
                     if isinstance(arg, Identifier):
                         subpatterns.append(IdentifierPattern(arg.name))
                     elif isinstance(arg, (IntLiteral, StrLiteral, BoolLiteral)):
                         subpatterns.append(LiteralPattern(arg.value))
                     else:
                         subpatterns.append(LiteralPattern(arg))
                 
                 pat_node = ConstructorPattern(pat_name, subpatterns)
             else:
                pat_node = LiteralPattern(pattern_expr)
             
             guard = None
             if self.match('if'):
                 guard = self.parse_expression()
             
             body = []
             if self.match('{'):
                 while not self.check('}'):
                     stmt = self.parse_statement()
                     if stmt: body.append(stmt)
                 self.consume(expected_value='}')
             elif self.match('->'):
                 stmt = self.parse_statement()
                 if stmt: body = [stmt]
             else:
                 # Maybe implicit block or just expr?
                 pass
                 
             cases.append(MatchCase(pat_node, guard, body))
             
        self.consume(expected_value='}')
        return MatchStmt(expr, cases)

    def parse_assert_stmt(self):
        self.consume(expected_value='assert')
        condition = self.parse_expression()
        message = None
        if self.match(','):
            message = self.parse_expression()
        
        # Check for optional semicolon
        if self.check(';'):
            self.consume()
            
        return AssertStmt(condition, message)

    def parse_case_stmt(self):
        self.consume(expected_value='case')
        pattern = self.parse_expression()
        
        guard = None
        if self.match('if'):
            guard = self.parse_expression()
            
        body = self.parse_block()
        return MatchCase(pattern, guard, body)

    # --- Expressions (Pratt Parser) ---
    def parse_expression(self, min_prec=0):
        # Prefix operators
        token = self.peek()
        if token.type == 'OP' and token.value in ('-', '!', '+', '~', '*', '**', '...') or token.value == 'not':
            op = token.value
            self.consume()
            # right associative, high precedence (say 13)
            rhs = self.parse_expression(13) 
            lhs = UnaryOp(op, operand=rhs)
        else:
            lhs = self.parse_primary()
        
        while True:
            pk = self.peek()
            op = None
            if pk.type == 'OP':
                op = pk.value
            elif pk.type == 'IDENT':
                if pk.value in ('in', 'is', 'and', 'or', 'as'):
                    op = pk.value
                    
                    # Handle 'not in' and 'is not'
                    if pk.value == 'not' and self.source[self.pos+3:].strip().startswith('in'): # weak check
                         # Better: peek next token
                         pass
                elif pk.value == 'not':
                     # Check if next is 'in'
                     # peek() uses self.pos. If we peek+1?
                     # Tokenizer pre-reads.
                     if self.pos + 1 < len(self.tokens) and self.tokens[self.pos+1].value == 'in':
                         op = 'not in'
                
                # Check for 'is not'
                if op == 'is':
                     if self.pos + 1 < len(self.tokens) and self.tokens[self.pos+1].value == 'not':
                         op = 'is not'
            
            if not op:
                break
                
            prec = self.get_precedence(op)
            
            if prec < min_prec or prec == 0:
                break
            
            # Special case for pipe |>
            if op == '|>':
                self.consume()
                rhs = self.parse_expression(prec + 1)
                lhs = PipeExpr(lhs, rhs)
                continue
            
            # Special case for range ..
            if op == '..' or op == '..<':
                self.consume()
                rhs = self.parse_expression(prec + 1)
                
                step = None
                if self.match('step'):
                    step = self.parse_expression(prec + 1)
                
                exclusive = (op == '..<')
                lhs = RangeExpr(lhs, rhs, exclusive=exclusive, step=step)
                continue
            
            # Special case for conditional ternary ? :
            if op == '?':
                self.consume() # eat ?
                true_expr = self.parse_expression(0)
                self.consume(expected_value=':')
                false_expr = self.parse_expression(min_prec)
                lhs = CondExpr(lhs, true_expr, false_expr) # lhs is the condition
                continue

            # Special case for null coalescing ??
            if op == '??':
                self.consume()
                rhs = self.parse_expression(prec) # right associative? usually left
                lhs = CoalesceExpr(lhs, rhs)
                continue

            # Special case for 'as' cast
            if op == 'as':
                self.consume()
                t_name = self.parse_type()
                rhs = Identifier(t_name)
                lhs = BinaryOp(lhs, 'as', rhs)
                continue

            self.consume() # consume first part of op (or whole op)
            if op == 'not in' or op == 'is not':
                self.consume() # consume 2nd part ('in' or 'not')
                
            rhs = self.parse_expression(prec + 1 if self.is_left_assoc(op) else prec)
            lhs = BinaryOp(lhs, op, rhs)
            
        return lhs

    def get_precedence(self, op):
        # Higher number = higher precedence
        precedences = {
            '=': 1, '+=': 1, '-=': 1,
            '?': 2, # Ternary
            'or': 3, '||': 3,
            'and': 4, '&&': 4,
            '==': 5, '!=': 5, '<': 6, '>': 6, '<=': 6, '>=': 6, 'in': 6, 'not in': 6, 'is': 6, 'is not': 6,
            '..': 7, '..<': 7, # Range
            '??': 8, '?:': 8, # Null coalescing/Elvis
            '+': 9, '-': 9,
            '*': 10, '/': 10, '%': 10, 'as': 10,
            '**': 11,
            '|>': 1, # Pipe usually low prec, handled separately?
            '.': 12, '[': 12, '(': 12, '?.': 12
        }
        return precedences.get(op, 0)
        
    def is_left_assoc(self, op):
        return op != '**' and op != '=' and op != '??'

    def parse_primary(self):
        token = self.peek()
        # print(f"DEBUG: parse_primary peek={token}")
        
        if token.type == 'INT':
            self.consume()
            return IntLiteral(token.value)
        elif token.type == 'FLOAT':
            self.consume()
            return FloatLiteral(token.value)
        elif token.type == 'STRING':
            self.consume()
            return StrLiteral(token.value)
        elif token.type == 'FSTRING':
            self.consume()
            return Identifier(f'f"{token.value}"') # Hack: preserve f-string as py ident for now
            
        elif token.type == 'IDENT':
            if token.value == 'true':
                self.consume()
                return BoolLiteral(True)
            elif token.value == 'false':
                self.consume()
                return BoolLiteral(False)
            elif token.value == 'null':
                self.consume()
                return NoneLiteral()
            # Lambda is handled via '(' ... '=>' or check special syntax if needed
            
            elif token.value == 'if':
                return self.parse_if_stmt()
            elif token.value == 'match':
                 return self.parse_match_stmt()
            
            self.consume()
            node = Identifier(token.value)
            return self.parse_postfix(node)
            
        elif token.value == '[':
            return self.parse_list_literal()
        elif token.value == '{':
            return self.parse_dict_or_block()
        elif token.value == '(':
            self.consume() # match (
            # Empty tuple () or () =>
            if self.check(')'):
                self.consume() # Consume the closing ')'
                if self.match('=>'):
                    # 0-arg lambda
                    body = self.parse_expression()
                    return LambdaExpr([], body)
                return TupleLiteral([])
                
            expr = self.parse_expression(0)
            
            # Check for Tuple: (expr, expr)
            if self.match(','):
                elements = [expr]
                while True:
                    if self.check(')'): break
                    elements.append(self.parse_expression())
                    if not self.match(','): break
                self.consume(expected_value=')')
                
                # Check for arrow function: (x, y) => ...
                if self.match('=>'):
                    params = []
                    for el in elements:
                        if isinstance(el, Identifier):
                            params.append(Parameter(el.name))
                        else:
                            raise SyntaxError("Invalid parameter in lambda")
                    
                    body = self.parse_expression()
                    return LambdaExpr(params, body)
                
                return TupleLiteral(elements)
                
            self.consume(expected_value=')')
            # Check for arrow function: (Params) => Expr
            if self.match('=>'):
                # expr is the params part. It could be Identifier or TupleLiteral or comma identifiers
                # We need to convert expr to list of Parameters
                params = []
                if isinstance(expr, Identifier):
                    params.append(Parameter(expr.name))
                elif isinstance(expr, TupleLiteral):
                    for el in expr.elements:
                        if isinstance(el, Identifier):
                            params.append(Parameter(el.name))
                        else:
                            # Complex pattern?
                            pass
                
                body = self.parse_expression() 
                # body might be BlockExpr if we support (x) => { ... } ?
                # The examples use (x) => x * 2 (expression).
                # Example 235: () => { ... }
                # But here we parse 'body' as Expression.
                # If body starts with {, it calls parse_dict_or_block.
                # parse_dict_or_block returns Dict or Set.
                # Wait, code blocks in expression pos?
                # parse_dict_or_block only returns Dict/Set.
                # We need to handle block logic if we want to support () => { stmt; }
                
                return LambdaExpr(params, body)
            
            return self.parse_postfix(expr)
            
        raise SyntaxError(f"Unexpected token {token} at {token.line}:{token.column}")

    def parse_lambda(self):
        self.consume(expected_value='fn')
        self.consume(expected_value='(')
        params = []
        if not self.check(')'):
             while True:
                p_name = self.consume(expected_type='IDENT').value
                params.append(Parameter(p_name))
                if not self.match(','): break
        self.consume(expected_value=')')
        self.consume(expected_value='{')
        body = []
        while not self.check('}'):
             stmt = self.parse_statement()
             if stmt: body.append(stmt)
        self.consume(expected_value='}')
        return LambdaExpr(params, BlockExpr(body))

    def parse_postfix(self, node):
        while True:
            # print(f"DEBUG: parse_postfix peek={self.peek()}")
            if self.match('('):
                args = []
                kwargs = {}
                if not self.check(')'):
                    while True:
                        # Check for named arg: IDENT :|= ...
                        is_named = False
                        if self.check_type('IDENT'):
                            # Need lookahead. pos is IDENT. next?
                            next_token_idx = self.pos + 1
                            if next_token_idx < len(self.tokens):
                                next_val = self.tokens[next_token_idx].value
                                if next_val in (':', '='):
                                    is_named = True
                        
                        if is_named:
                            key = self.consume().value # Consume IDENT
                            self.consume() # Consume : or =
                            val = self.parse_expression()
                            kwargs[key] = val
                        else:
                            if kwargs:
                                raise SyntaxError("Positional argument follows keyword argument")
                            args.append(self.parse_expression())
                            
                        if not self.match(','):
                            break
                self.consume(expected_value=')')
                node = CallExpr(node, args, kwargs)
            elif self.peek().value == '{':
                # Struct initialization: User { x: 1 }
                # Ambiguity with control flow: if x { ... } vs if x {} ...
                # Heuristic: Only allow if node is Capitalized Identifier (or member access)
                is_struct = False
                if isinstance(node, Identifier) and node.name[0].isupper():
                    is_struct = True
                elif isinstance(node, BinaryOp) and node.op == '.':
                     # Check rhs
                     if isinstance(node.rhs, Identifier) and node.rhs.name[0].isupper():
                         is_struct = True
                
                if is_struct:
                    self.consume()
                    d = self.parse_dict_body() # parse content and closing '}'
                    # Create CallExpr with SpreadExpr(d, is_dict=True)
                    node = CallExpr(node, [SpreadExpr(d, is_dict=True)])
                else:
                    break # Not struct init, treat as end of expression (block starts)
            elif self.match('['):
                index = self.parse_expression()
                self.consume(expected_value=']')
                node = IndexExpr(node, index)
            elif self.match('.'):
                member = self.consume(expected_type='IDENT').value
                node = MemberExpr(node, member)
            elif self.match('?.'): # Safe nav
                member = self.consume(expected_type='IDENT').value
                node = SafeNavExpr(node, member, is_index=False)
            elif self.match('?['): # Safe index
                index = self.parse_expression()
                self.consume(expected_value=']')
                node = SafeNavExpr(node, index, is_index=True)
            else:
                break
        return node
        
    def parse_list_literal(self):
        self.consume(expected_value='[')
        if self.match(']'):
            return ListLiteral([])
            
        if self.match('*') or self.match('...'):
            first = SpreadExpr(self.parse_expression(), is_dict=False)
        else:
            first = self.parse_expression()
        
        # Check for comprehension: [x for x in list]
        if self.match('for'):
             comprehensions = []
             # First for was already matched
             while True:
                 # Support full pattern (e.g. k, v or (k, v))
                 pattern = self.parse_expression(7)
                 if self.match(','):
                     pats = [pattern]
                     while True:
                         pats.append(self.parse_expression(7))
                         if not self.match(','): break
                     pattern = TupleLiteral(pats)
                 
                 self.consume(expected_value='in')
                 iterable = self.parse_expression()
                 filters = []
                 if self.match('if'):
                     filters.append(self.parse_expression())
                 
                 comprehensions.append((pattern, iterable, filters))
                 
                 if not self.match('for'):
                     break
                 
             self.consume(expected_value=']')
             return ComprehensionExpr(first, comprehensions, expr_type='list')
        
        elements = [first]
        while self.match(','):
            if self.check(']'): break
            if self.match('*') or self.match('...'):
                elements.append(SpreadExpr(self.parse_expression(), is_dict=False))
            else:
                elements.append(self.parse_expression())
        
        self.consume(expected_value=']')
        return ListLiteral(elements)

    def parse_dict_or_block(self):
         self.consume(expected_value='{')
         return self.parse_dict_body()

    def parse_dict_body(self):
        if self.match('}'):
            return DictLiteral([])
        
        # Heuristic: Check for statement keywords -> Block
        tok = self.peek()
        stmt_keywords = ('let', 'const', 'return', 'while', 'for', 'if', 'try', 'match', 'guard', 'unless')
        if tok.value in stmt_keywords:
            return self.parse_block_expr_internal(first_stmt=None)
            
        # Parsing logic handles Dict (with spread) vs Set vs Block
        elements = []
        is_dict = False
        
        while not self.check('}'):
            if self.match('**') or self.match('...'):
                expr = self.parse_expression()
                elements.append(SpreadExpr(expr, is_dict=True))
                is_dict = True
            elif self.match('*'):
                expr = self.parse_expression()
                elements.append(SpreadExpr(expr, is_dict=False))
            else:
                expr = self.parse_expression()
                if self.match(':'):
                    val = self.parse_expression()
                    if self.match('for'):
                        return self.parse_dict_comp_body(expr, val)
                    elements.append((expr, val))
                    is_dict = True
                else:
                    if self.match('for'):
                        return self.parse_set_comp_body(expr)
                    elements.append(expr)
            if not self.match(','): break
            
        self.consume(expected_value='}')
        if is_dict: return DictLiteral(elements)
        else: return SetLiteral(elements)
            
    def parse_dict_comp_body(self, key, val):
        comprehensions = []
        while True:
            pattern = self.parse_expression(7)
            if self.match(','):
                pats = [pattern]
                while True:
                    pats.append(self.parse_expression(7))
                    if not self.match(','): break
                pattern = TupleLiteral(pats)
            self.consume(expected_value='in')
            iterable = self.parse_expression()
            filters = []
            if self.match('if'):
                filters.append(self.parse_expression())
            comprehensions.append((pattern, iterable, filters))
            if not self.match('for'): break
        self.consume(expected_value='}')
        return ComprehensionExpr((key, val), comprehensions, expr_type='dict')

    def parse_set_comp_body(self, first):
        comprehensions = []
        while True:
            pattern = self.parse_expression(7)
            if self.match(','):
                pats = [pattern]
                while True:
                    pats.append(self.parse_expression(7))
                    if not self.match(','): break
                pattern = TupleLiteral(pats)
            self.consume(expected_value='in')
            iterable = self.parse_expression()
            filters = []
            if self.match('if'):
                filters.append(self.parse_expression())
            comprehensions.append((pattern, iterable, filters))
            if not self.match('for'): break
        self.consume(expected_value='}')
        return ComprehensionExpr(first, comprehensions, expr_type='set')

    def parse_block_expr_internal(self, first_stmt=None):
        statements = []
        if first_stmt:
            statements.append(first_stmt)
            
        while not self.check('}') and not self.check('EOF'):
            stmt = self.parse_statement()
            if stmt: statements.append(stmt)
            
        self.consume(expected_value='}')
        return BlockExpr(statements)

def parse_file(path: str) -> Program:
    """Parse Aura file using recursive descent parser."""
    with open(path, 'r', encoding='utf-8') as f:
        source = f.read()
    tokenizer = Tokenizer(source)
    tokens = tokenizer.tokenize()
    parser = Parser(tokens)
    return parser.parse()

def parse_value(value_str: str) -> Node:
    """Parse a single expression/value string."""
    tokenizer = Tokenizer(value_str)
    tokens = tokenizer.tokenize()
    parser = Parser(tokens)
    return parser.parse_expression()
